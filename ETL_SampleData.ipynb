{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read config file for AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://28f63b91b31c:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f36d0631198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process song data (sample)\n",
    "### **EXPLORATION ONLY - DOES NOT WRITE PARQUET FILES** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "input_data = \"data/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from S3...\n",
      "-RECORD 0--------------------------------\n",
      " artist_id        | ARDR4AC1187FB371A1   \n",
      " artist_latitude  | null                 \n",
      " artist_location  |                      \n",
      " artist_longitude | null                 \n",
      " artist_name      | Montserrat Caball... \n",
      " duration         | 511.16363            \n",
      " num_songs        | 1                    \n",
      " song_id          | SOBAYLL12A8C138AF9   \n",
      " title            | Sono andati? Fing... \n",
      " year             | 0                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get filepath to song data file\n",
    "song_data = \"{}/song_data/*/*/*/*.json\".format(input_data)\n",
    "\n",
    "# read song data file\n",
    "print ('Reading data from S3...')\n",
    "df_song = spark.read.json(song_data)\n",
    "\n",
    "# Sample record of raw song data\n",
    "df_song.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------\n",
      " song_id   | SOGOSOV12AF72A285E \n",
      " title     | ¿Dónde va Chichi?  \n",
      " artist_id | ARGUVEV1187B98BA17 \n",
      " year      | 1997               \n",
      " duration  | 313.12934          \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = df_song.select(\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\").dropDuplicates()\n",
    "# sample record of song table\n",
    "songs_table.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " artist_id   | ARGUVEV1187B98BA17 \n",
      " artist_name | Sierra Maestra     \n",
      " location    |                    \n",
      " lat         | null               \n",
      " lon         | null               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = df_song.selectExpr(\"artist_id\", \n",
    "                          \"artist_name\",\n",
    "                          \"artist_location as location\", \n",
    "                          \"artist_latitude as lat\", \n",
    "                          \"artist_longitude as lon\").dropDuplicates()\n",
    "# sample record from artist table \n",
    "artists_table.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Harmonia             \n",
      " auth          | Logged In            \n",
      " firstName     | Ryan                 \n",
      " gender        | M                    \n",
      " itemInSession | 0                    \n",
      " lastName      | Smith                \n",
      " length        | 655.77751            \n",
      " level         | free                 \n",
      " location      | San Jose-Sunnyval... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1.541016707796E12    \n",
      " sessionId     | 583                  \n",
      " song          | Sehr kosmisch        \n",
      " status        | 200                  \n",
      " ts            | 1542241826796        \n",
      " userAgent     | \"Mozilla/5.0 (X11... \n",
      " userId        | 26                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data =\"{}/log_data/*.json\".format(input_data)\n",
    "\n",
    "# read log data file\n",
    "df_log = spark.read.json(log_data)\n",
    "\n",
    "# sample record from raw log file\n",
    "df_log.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------\n",
      " userid    | 26    \n",
      " firstname | Ryan  \n",
      " lastname  | Smith \n",
      " gender    | M     \n",
      " level     | free  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns for users table    \n",
    "users_table = df_log.filter(df_log.page == 'NextSong').selectExpr(\"userid\",\n",
    "                                                                  \"firstname\",\n",
    "                                                                  \"lastname\",\n",
    "                                                                  \"gender\",\n",
    "                                                                  \"level\").dropDuplicates()\n",
    "# sample record from users table\n",
    "users_table.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up UDFs for timeparsing \n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp(x / 1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df_log = df_log.withColumn(\"time_stamp\", get_datetime(df_log.ts))\n",
    "#hour\n",
    "get_hour = udf(lambda x: datetime.fromtimestamp(x / 1000.0).hour)\n",
    "df_log = df_log.withColumn(\"hour\", get_hour(df_log.ts))\n",
    "#day\n",
    "get_day = udf(lambda x: datetime.fromtimestamp(x / 1000.0).day)\n",
    "df_log = df_log.withColumn(\"day\", get_day(df_log.ts))\n",
    "#month\n",
    "get_month = udf(lambda x: datetime.fromtimestamp(x / 1000.0).month)\n",
    "df_log = df_log.withColumn(\"month\", get_month(df_log.ts))\n",
    "#year\n",
    "get_year = udf(lambda x: datetime.fromtimestamp(x / 1000.0).year)\n",
    "df_log = df_log.withColumn(\"year\", get_year(df_log.ts))\n",
    "# weekday\n",
    "get_dow = udf(lambda x: datetime.fromtimestamp(x / 1000.0).weekday())\n",
    "df_log = df_log.withColumn(\"dow\", get_dow(df_log.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Harmonia             \n",
      " auth          | Logged In            \n",
      " firstName     | Ryan                 \n",
      " gender        | M                    \n",
      " itemInSession | 0                    \n",
      " lastName      | Smith                \n",
      " length        | 655.77751            \n",
      " level         | free                 \n",
      " location      | San Jose-Sunnyval... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1.541016707796E12    \n",
      " sessionId     | 583                  \n",
      " song          | Sehr kosmisch        \n",
      " status        | 200                  \n",
      " ts            | 1542241826796        \n",
      " userAgent     | \"Mozilla/5.0 (X11... \n",
      " userId        | 26                   \n",
      " time_stamp    | 2018-11-15 00:30:26  \n",
      " hour          | 0                    \n",
      " day           | 15                   \n",
      " month         | 11                   \n",
      " year          | 2018                 \n",
      " dow           | 3                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample record from log data with time parsing \n",
    "df_log.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " ts         | 1542281082796       \n",
      " time_stamp | 2018-11-15 11:24:42 \n",
      " hour       | 11                  \n",
      " day        | 15                  \n",
      " month      | 11                  \n",
      " year       | 2018                \n",
      " dow        | 3                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create time table\n",
    "time_table = df_log.selectExpr(\"ts\", \"time_stamp\", \"hour\",\"day\",\"month\",\"year\", \"dow\").dropDuplicates()\n",
    "# sample record from time table\n",
    "time_table.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Songplays data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " artist           | Lionel Richie        \n",
      " auth             | Logged In            \n",
      " firstName        | Aleena               \n",
      " gender           | F                    \n",
      " itemInSession    | 40                   \n",
      " lastName         | Kirby                \n",
      " length           | 265.89995            \n",
      " level            | paid                 \n",
      " location         | Waterloo-Cedar Fa... \n",
      " method           | PUT                  \n",
      " page             | NextSong             \n",
      " registration     | 1.541022995796E12    \n",
      " sessionId        | 619                  \n",
      " song             | Lady                 \n",
      " status           | 200                  \n",
      " ts               | 1542313967796        \n",
      " userAgent        | Mozilla/5.0 (Maci... \n",
      " userId           | 44                   \n",
      " time_stamp       | 2018-11-15 20:32:47  \n",
      " hour             | 20                   \n",
      " day              | 15                   \n",
      " month            | 11                   \n",
      " year             | 2018                 \n",
      " dow              | 3                    \n",
      " artist_id        | ARIK43K1187B9AE54C   \n",
      " artist_latitude  | null                 \n",
      " artist_location  | Beverly Hills, CA    \n",
      " artist_longitude | null                 \n",
      " artist_name      | Lionel Richie        \n",
      " duration         | 307.3824             \n",
      " num_songs        | 1                    \n",
      " song_id          | SOBONFF12A6D4F84D8   \n",
      " title            | Tonight Will Be A... \n",
      " year             | 1986                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join song and log data dataframes \n",
    "songplays = df_log.join(df_song, df_log.artist==df_song.artist_name)\n",
    "# sample record from songplays data \n",
    "songplays.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " ts          | 1542641764796        \n",
      " artist_id   | ARXR32B1187FB57099   \n",
      " song_id     | SOFSOCN12A8C143F5D   \n",
      " sessionid   | 724                  \n",
      " location    | San Francisco-Oak... \n",
      " useragent   | Mozilla/5.0 (Wind... \n",
      " userid      | 49                   \n",
      " time_stamp  | 2018-11-19 15:36:04  \n",
      " year        | 2018                 \n",
      " month       | 11                   \n",
      " songplay_id | 8                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table \n",
    "songplays_table = songplays.selectExpr(\"ts\", \"artist_id\", \"song_id\", \"sessionid\",\"location\",\"useragent\", \"userid\").withColumn(\n",
    "    \"time_stamp\", get_datetime(df_log.ts)).withColumn(\n",
    "    \"year\", get_year(df_log.ts)).withColumn(\n",
    "    \"month\", get_month(df_log.ts)).withColumn(\n",
    "    \"songplay_id\", monotonically_increasing_id()).dropDuplicates()\n",
    "\n",
    "# sample record from songplays_table\n",
    "songplays_table.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|month|cnt|\n",
      "+-----+---+\n",
      "|   11| 21|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Songplays per month\n",
    "songplays_table.createOrReplaceTempView(\"songplays_table\")\n",
    "sample = spark.sql('SELECT month, count(*) as cnt  FROM songplays_table group by month order by month')\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+\n",
      "|hour|      artist_name|count(1)|\n",
      "+----+-----------------+--------+\n",
      "|   3|Sophie B. Hawkins|       1|\n",
      "|   7|      Lupe Fiasco|       1|\n",
      "|   7|        Tom Petty|       1|\n",
      "|   9|        Tom Petty|       1|\n",
      "|  12|    Lionel Richie|       1|\n",
      "|  13|      Lupe Fiasco|       1|\n",
      "|  15|       Blue Rodeo|       1|\n",
      "|  15|              Gob|       1|\n",
      "|  15|    Lionel Richie|       1|\n",
      "|  16|      Lupe Fiasco|       1|\n",
      "|  17|           Trafik|       1|\n",
      "|  18|      Lupe Fiasco|       1|\n",
      "|  20|     Gwen Stefani|       1|\n",
      "|  20|     Jimmy Wakely|       1|\n",
      "|  20|      Line Renaud|       1|\n",
      "|  20|    Lionel Richie|       2|\n",
      "|  20|        Tom Petty|       1|\n",
      "|  21|            Elena|       1|\n",
      "|  22|        Tom Petty|       1|\n",
      "|  23|      Lupe Fiasco|       1|\n",
      "+----+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soung popularity by time of day\n",
    "time_table.createOrReplaceTempView(\"time_table\")\n",
    "artists_table.createOrReplaceTempView(\"artists_table\")\n",
    "\n",
    "sample2 = spark.sql('''\n",
    "SELECT t.hour, a.artist_name, COUNT(*)\n",
    "FROM songplays_table s\n",
    "JOIN time_table t\n",
    "ON s.ts=t.ts\n",
    "JOIN artists_table a\n",
    "ON s.artist_id=a.artist_id\n",
    "GROUP BY t.hour, a.artist_name\n",
    "ORDER BY cast(t.hour as int), a.artist_name\n",
    "''')\n",
    "sample2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
